{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWchGPfa9xW9"
   },
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression as logreg\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score ,roc_auc_score as auc, accuracy_score as acc, confusion_matrix, roc_curve, precision_score, recall_score, precision_recall_curve,average_precision_score,average_precision_score as aps,log_loss as ll\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3051,
     "status": "ok",
     "timestamp": 1559907752330,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh5.googleusercontent.com/-72ZtNB76Qxg/AAAAAAAAAAI/AAAAAAAAAAc/Nsa5vQruND0/s64/photo.jpg",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "NB5xYyHg9xXA",
    "outputId": "7eaac4d1-42cd-4178-96e1-e9ccabc75020",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "0         0  22.0   7.2500         0         0         1           0   \n",
       "1         1  38.0  71.2833         1         0         0           1   \n",
       "2         1  26.0   7.9250         0         0         1           1   \n",
       "3         1  35.0  53.1000         1         0         0           1   \n",
       "4         0  35.0   8.0500         0         0         1           0   \n",
       "\n",
       "   Sex_male  SibSp_0  SibSp_1  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0         1        0        1  ...        1        0        0        0   \n",
       "1         0        0        1  ...        1        0        0        0   \n",
       "2         0        1        0  ...        1        0        0        0   \n",
       "3         0        0        1  ...        1        0        0        0   \n",
       "4         1        1        0  ...        1        0        0        0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0        0        0        0           0           0           1  \n",
       "1        0        0        0           1           0           0  \n",
       "2        0        0        0           0           0           1  \n",
       "3        0        0        0           0           0           1  \n",
       "4        0        0        0           0           0           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_cleaned.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='Survived'         \n",
    "model= logreg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived        int64\n",
       "Age           float64\n",
       "Fare          float64\n",
       "Pclass_1        int64\n",
       "Pclass_2        int64\n",
       "Pclass_3        int64\n",
       "Sex_female      int64\n",
       "Sex_male        int64\n",
       "SibSp_0         int64\n",
       "SibSp_1         int64\n",
       "SibSp_2         int64\n",
       "SibSp_3         int64\n",
       "SibSp_4         int64\n",
       "SibSp_5         int64\n",
       "SibSp_8         int64\n",
       "Parch_0         int64\n",
       "Parch_1         int64\n",
       "Parch_2         int64\n",
       "Parch_3         int64\n",
       "Parch_4         int64\n",
       "Parch_5         int64\n",
       "Parch_6         int64\n",
       "Embarked_C      int64\n",
       "Embarked_Q      int64\n",
       "Embarked_S      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### segegating variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2634,
     "status": "ok",
     "timestamp": 1559907752332,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh5.googleusercontent.com/-72ZtNB76Qxg/AAAAAAAAAAI/AAAAAAAAAAc/Nsa5vQruND0/s64/photo.jpg",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "rym4fnPq9xXG",
    "outputId": "103a10b9-f5d8-4ae3-e3a1-c42a9a1a42f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 24), (891,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seperating independent and dependent variables\n",
    "x = data.drop([target], axis=1)\n",
    "y = data[target]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "0         0  22.0   7.2500         0         0         1           0   \n",
       "1         1  38.0  71.2833         1         0         0           1   \n",
       "2         1  26.0   7.9250         0         0         1           1   \n",
       "3         1  35.0  53.1000         1         0         0           1   \n",
       "4         0  35.0   8.0500         0         0         1           0   \n",
       "\n",
       "   Sex_male  SibSp_0  SibSp_1  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0         1        0        1  ...        1        0        0        0   \n",
       "1         0        0        1  ...        1        0        0        0   \n",
       "2         0        1        0  ...        1        0        0        0   \n",
       "3         0        0        1  ...        1        0        0        0   \n",
       "4         1        1        0  ...        1        0        0        0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0        0        0        0           0           0           1  \n",
       "1        0        0        0           1           0           0  \n",
       "2        0        0        0           0           0           1  \n",
       "3        0        0        0           0           0           1  \n",
       "4        0        0        0           0           0           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Age           0\n",
       "Fare          0\n",
       "Pclass_1      0\n",
       "Pclass_2      0\n",
       "Pclass_3      0\n",
       "Sex_female    0\n",
       "Sex_male      0\n",
       "SibSp_0       0\n",
       "SibSp_1       0\n",
       "SibSp_2       0\n",
       "SibSp_3       0\n",
       "SibSp_4       0\n",
       "SibSp_5       0\n",
       "SibSp_8       0\n",
       "Parch_0       0\n",
       "Parch_1       0\n",
       "Parch_2       0\n",
       "Parch_3       0\n",
       "Parch_4       0\n",
       "Parch_5       0\n",
       "Parch_6       0\n",
       "Embarked_C    0\n",
       "Embarked_Q    0\n",
       "Embarked_S    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the train test split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y = train_test_split(x,y,test_size=1/4,random_state= r)\n",
    "train_x,val_x,train_y,val_y= train_test_split(train_x, train_y, test_size=1/3,random_state=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Fare', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female',\n",
       "       'Sex_male', 'SibSp_0', 'SibSp_1', 'SibSp_2', 'SibSp_3', 'SibSp_4',\n",
       "       'SibSp_5', 'SibSp_8', 'Parch_0', 'Parch_1', 'Parch_2', 'Parch_3',\n",
       "       'Parch_4', 'Parch_5', 'Parch_6', 'Embarked_C', 'Embarked_Q',\n",
       "       'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_x.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.DataFrame(scaler.fit_transform(train_x),columns=cols)\n",
    "test_x = pd.DataFrame(scaler.fit_transform(test_x),columns=cols)\n",
    "val_x = pd.DataFrame(scaler.fit_transform(val_x),columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2906,
     "status": "ok",
     "timestamp": 1559907754529,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh5.googleusercontent.com/-72ZtNB76Qxg/AAAAAAAAAAI/AAAAAAAAAAc/Nsa5vQruND0/s64/photo.jpg",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "TFrwDTRdybYF",
    "outputId": "be6a8867-192c-445b-a4ef-6ef855d43c89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYz-N4EVPapW"
   },
   "source": [
    "### Making predictions using *predict_proba* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3219,
     "status": "ok",
     "timestamp": 1559907756195,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh5.googleusercontent.com/-72ZtNB76Qxg/AAAAAAAAAAI/AAAAAAAAAAc/Nsa5vQruND0/s64/photo.jpg",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "TdyhO6NmdZ4_",
    "outputId": "1f9f1cb2-0f48-4d3f-951a-d42ee572bc44"
   },
   "outputs": [],
   "source": [
    "# Predicting over the Train\n",
    "train_predict = model.predict_proba(val_x)\n",
    "train_preds = train_predict[:,1]\n",
    "train_pred=train_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "break value of predicted values to make them 0 or 1 depending if their predicted probabilities are lesser or greater than break value ,we use different break values to see where the evaluation metric is most satisfied and that is right break value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the code gives the best breakvalue = breakval_ corresponding to the eval metrics in thresh_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update thresh_metric, threshlist ,scorelist,threshlist1 ,scorelist1 and breakval1(initialization only) to use desired eval metrics to compute best break value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the values of eval metric in thresh_metric corresponding to those of breakval list is in threshlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the best metric for threshhold evaluation is auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_metric=['auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " at break value of  0.38800000000000007 the auc score attains a maximum of 0.7595907928388745\n"
     ]
    }
   ],
   "source": [
    "tc=-1\n",
    "breakval_=[]\n",
    "indexlist1=[]\n",
    "indexlist=[]\n",
    "breakval1=[[],[],[]]\n",
    "corrscorelist=[]\n",
    "\n",
    "for k in thresh_metric:\n",
    " tc=tc+1\n",
    " breakval=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    " \n",
    " auclist=[]\n",
    " threshlist=[auclist]\n",
    " for j in breakval:\n",
    "  for i in range(0, len(train_preds)):\n",
    "   if(train_preds[i]>j):\n",
    "    train_pred[i] = 1\n",
    "   else:\n",
    "    train_pred[i] = 0\n",
    "\n",
    "  auc=roc_auc_score(val_y, train_pred)\n",
    "  scorelist=[auc]\n",
    "  threshlist[tc].append(scorelist[tc])\n",
    "  train_preds = model.predict_proba(val_x)[:,1]\n",
    " max=0\n",
    " c=-1\n",
    "\n",
    " for i in threshlist[tc]:\n",
    "  c=c+1 \n",
    "  \n",
    "  if (i>max):\n",
    "    index=c\n",
    "    max=i   \n",
    " indexlist.append(index)\n",
    "\n",
    " auclist1=[]\n",
    " threshlist1=[auclist1]\n",
    " a=breakval[indexlist[tc]]-breakval[indexlist[tc]]/10\n",
    " breakval1[tc]=[]\n",
    " while a<(breakval[indexlist[tc]]+breakval[indexlist[tc]]/10):\n",
    "  for i in range(0, len(train_preds)):\n",
    "   if(train_preds[i]>a):\n",
    "    train_pred[i] = 1\n",
    "   else:\n",
    "    train_pred[i] = 0\n",
    "    \n",
    "  auc1=roc_auc_score(val_y, train_pred)\n",
    "  \n",
    "  scorelist1=[auc1]\n",
    "  a=a+breakval[indexlist[tc]]/100\n",
    "  threshlist1[tc].append(scorelist1[tc])\n",
    "  breakval1[tc].append(a)\n",
    " max=0\n",
    " c1=-1\n",
    " for i in threshlist1[tc]:\n",
    "  c1=c1+1 \n",
    "  \n",
    "  if (i>max):\n",
    "    \n",
    "    index1=c1\n",
    "    max=i\n",
    " indexlist1.append(index1)\n",
    " \n",
    " breakval_.append(breakval1[tc][indexlist1[tc]])\n",
    " for i in range(0, len(train_preds)):\n",
    "  if(train_preds[i]>breakval_[tc]):\n",
    "    train_pred[i] = 1\n",
    "  else:\n",
    "    train_pred[i] = 0\n",
    " corrscore=threshlist1[tc][indexlist1[tc]]\n",
    " corrscorelist.append(corrscore)                         \n",
    " print(\" at break value of \",breakval_[tc],\"the \"+str(k)+\" score attains a maximum of\",corrscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>breakvalue</th>\n",
       "      <td>0.388000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corresponding score</th>\n",
       "      <td>0.759591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          auc\n",
       "breakvalue           0.388000\n",
       "corresponding score  0.759591"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshtable=pd.DataFrame([breakval_,corrscorelist],columns=thresh_metric,index=['breakvalue','corresponding score'])\n",
    "threshtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexlist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.36400000000000005,\n",
       "  0.36800000000000005,\n",
       "  0.37200000000000005,\n",
       "  0.37600000000000006,\n",
       "  0.38000000000000006,\n",
       "  0.38400000000000006,\n",
       "  0.38800000000000007,\n",
       "  0.39200000000000007,\n",
       "  0.3960000000000001,\n",
       "  0.4000000000000001,\n",
       "  0.4040000000000001,\n",
       "  0.4080000000000001,\n",
       "  0.4120000000000001,\n",
       "  0.4160000000000001,\n",
       "  0.4200000000000001,\n",
       "  0.4240000000000001,\n",
       "  0.4280000000000001,\n",
       "  0.4320000000000001,\n",
       "  0.4360000000000001,\n",
       "  0.4400000000000001],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakval1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38800000000000007]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakval_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predicted probabilities become 0 or 1 depending if they are lesser or greater than break value=breakval_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(train_preds)):\n",
    "   if(train_preds[i]>breakval_):\n",
    "    train_pred[i] = 1\n",
    "   else:\n",
    "    train_pred[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N FOLD CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to change eval metric throughout the code make corresponding changes in the eval_metric and cv_score() and eval_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nfold=9\n",
    "eval_metric=['recall','f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the function takes the ml algorithm,columns of datatable and the break value as parameter . function randomly chooses nfold sets of train and validation sets where in each fold val set is complement of train set and the union of validation sets in all folds gives the dataset itself . each fold is trained on train set and tested on validation set and gives a set of evaluation metric scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cv_score(ml_model=model, rstate = r, thres = breakval_, cols = x.columns.tolist()):\n",
    "    i = 1\n",
    "    cv_scores = []\n",
    "    df1 = data.copy()\n",
    "    df1 = data[cols]\n",
    "    recalllist,f1list=[[],[]]\n",
    "    indexlist=[]\n",
    "    \n",
    "    # 5 Fold cross validation stratified on the basis of target\n",
    "    kf = StratifiedKFold(n_splits=nfold,random_state=rstate,shuffle=True)\n",
    "    for df_index,test_index in kf.split(df1,y):\n",
    "        \n",
    "        xtr,xvl = [df1.loc[df_index],df1.loc[test_index]]\n",
    "        ytr,yvl = [y.loc[df_index],y.loc[test_index]]\n",
    "            \n",
    "        # Define model for fitting on the training set for each fold\n",
    "        model = ml_model\n",
    "        model.fit(xtr, ytr)\n",
    "        pred_probs = model.predict_proba(xvl)\n",
    "        pp = []\n",
    "         \n",
    "        # Use threshold to define the classes based on probability values\n",
    "        for j in pred_probs[:,1]:\n",
    "            if j>thres:\n",
    "                pp.append(1)\n",
    "            else:\n",
    "                pp.append(0)\n",
    "         \n",
    "        # Calculate scores for each fold and print\n",
    "        pred_val = pp\n",
    "        \n",
    "        recall = recall_score(yvl,pred_val)\n",
    "        f1score=f1(yvl,pred_val)\n",
    "      \n",
    "    \n",
    "        recalllist.append(recall)\n",
    "        f1list.append(f1score)\n",
    "        \n",
    "         # Save scores\n",
    "        indexlist.append((\"kfold \"+str((i))))\n",
    "        i=i+1\n",
    "        \n",
    "    cv_score=pd.DataFrame([recalllist,f1list],index=eval_metric,columns=indexlist)\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kfold 1</th>\n",
       "      <th>kfold 2</th>\n",
       "      <th>kfold 3</th>\n",
       "      <th>kfold 4</th>\n",
       "      <th>kfold 5</th>\n",
       "      <th>kfold 6</th>\n",
       "      <th>kfold 7</th>\n",
       "      <th>kfold 8</th>\n",
       "      <th>kfold 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         kfold 1   kfold 2   kfold 3   kfold 4   kfold 5   kfold 6   kfold 7  \\\n",
       "recall  0.710526  0.684211  0.815789  0.789474  0.684211  0.815789  0.763158   \n",
       "f1      0.720000  0.666667  0.746988  0.789474  0.675325  0.756098  0.716049   \n",
       "\n",
       "         kfold 8   kfold 9  \n",
       "recall  0.789474  0.842105  \n",
       "f1      0.750000  0.761905  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def eval_score(ml_model=model, rstate = r, thres = breakval_, cols =x.columns.tolist()):\n",
    "        i = 1\n",
    "        eval_scores = []\n",
    "        \n",
    "       \n",
    "        indexlist=[]\n",
    "    \n",
    "        # Define model for fitting on the training set for each fold\n",
    "        model = ml_model\n",
    "        model.fit(train_x[cols],train_y)\n",
    "        pred_probs = model.predict_proba(val_x[cols])\n",
    "        pp = []\n",
    "         \n",
    "        # Use threshold to define the classes based on probability values\n",
    "        for j in pred_probs[:,1]:\n",
    "            if j>thres:\n",
    "                pp.append(1)\n",
    "            else:\n",
    "                pp.append(0)\n",
    "         \n",
    "        # Calculate scores for each fold and print\n",
    "        pred_val = pp\n",
    "        recall = recall_score(val_y,pred_val)\n",
    "        f1score=f1(val_y,pred_val)\n",
    "         # Save scores\n",
    "        indexlist.append((\"kfold \"+str((i))))\n",
    "        i=i+1\n",
    "        \n",
    "        eval_score=pd.DataFrame([recall,f1score],index=eval_metric,columns=['score'])\n",
    "        return eval_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.710660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score\n",
       "recall  0.823529\n",
       "f1      0.710660"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a ranking of features based on how significant they are to our analysis according to RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Create the RFE object and rank each feature\n",
    "\n",
    "rfe = RFE(estimator=model, n_features_to_select=1, step=1)\n",
    "rfe.fit(train_x, train_y)\n",
    "ranking_df = pd.DataFrame()\n",
    "ranking_df['Feature_name'] = x.iloc[0,].index\n",
    "ranking_df['Rank'] = rfe.ranking_\n",
    "ranked = ranking_df.sort_values(by=['Rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_name</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sex_female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SibSp_4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SibSp_3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SibSp_1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SibSp_8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Parch_6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SibSp_2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SibSp_0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Parch_1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Parch_4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Parch_3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Parch_0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Parch_2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Parch_5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SibSp_5</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_name  Rank\n",
       "5    Sex_female     1\n",
       "2      Pclass_1     2\n",
       "0           Age     3\n",
       "11      SibSp_4     4\n",
       "10      SibSp_3     5\n",
       "6      Sex_male     6\n",
       "8       SibSp_1     7\n",
       "23   Embarked_S     8\n",
       "4      Pclass_3     9\n",
       "13      SibSp_8    10\n",
       "20      Parch_6    11\n",
       "9       SibSp_2    12\n",
       "7       SibSp_0    13\n",
       "15      Parch_1    14\n",
       "21   Embarked_C    15\n",
       "1          Fare    16\n",
       "18      Parch_4    17\n",
       "17      Parch_3    18\n",
       "14      Parch_0    19\n",
       "16      Parch_2    20\n",
       "3      Pclass_2    21\n",
       "22   Embarked_Q    22\n",
       "19      Parch_5    23\n",
       "12      SibSp_5    24"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def noof_features_metric(nrank):\n",
    "  sco_featlist=[]\n",
    "  for i in eval_metric:\n",
    "    sco_feat=eval_score(cols = ranked['Feature_name'].iloc[:(nrank)].values.tolist()).score[i]\n",
    "    sco_featlist.append(sco_feat)\n",
    "  return pd.DataFrame(sco_featlist,index=eval_metric,columns=[\"rfe top\"+str(nrank)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculating no of top features to be taken in the model(acc to rfe) with respect to a evaluation metric which maximises that particular evaluation metric  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn_feat=0\n",
    "c=-1\n",
    "topfeatlist=[]\n",
    "topfeatscorelist=[]\n",
    "for i in eval_metric:\n",
    " c=c+1\n",
    " score=0\n",
    " max=0\n",
    " for j in range(1,len(x.columns.tolist())):\n",
    "  score=noof_features_metric(j).iloc[c].values\n",
    "  if(score>max):\n",
    "    max=score\n",
    "    topn_feat=j\n",
    " topfeatlist.append(topn_feat)\n",
    " topfeatscorelist.append(max)\n",
    "topfeat=pd.DataFrame([topfeatlist,topfeatscorelist],columns=eval_metric,index=[\"rfe top feat\",\"corresponding score\"])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rfe top feat</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corresponding score</th>\n",
       "      <td>[0.8235294117647058]</td>\n",
       "      <td>[0.7106598984771573]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   recall                    f1\n",
       "rfe top feat                           19                    19\n",
       "corresponding score  [0.8235294117647058]  [0.7106598984771573]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topfeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with main columns with respect to each evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the f1 score has top 19 features (chosen by rfe) where the evaluation metric recall reaches the highest score: [0.82352941] compared to other combination of feature used to make the model = 0.7666666666666666\n",
      "confusion matrix is :  [[112  23]\n",
      " [ 19  69]]\n",
      "the f1 score has top 19 features (chosen by rfe) where the evaluation metric f1 reaches the highest score: [0.7106599] compared to other combination of feature used to make the model = 0.7666666666666666\n",
      "confusion matrix is :  [[112  23]\n",
      " [ 19  69]]\n"
     ]
    }
   ],
   "source": [
    "predicted_wrt_evaluationmetrics=[]\n",
    "f1score,recalllist,test_colslist, topncollist,indexlist=[[],[],[],[],[]]\n",
    "for i in range(len(eval_metric)):\n",
    " testmetric=eval_metric[i]\n",
    " topn_feat=topfeat[testmetric][0]\n",
    " test_cols= ranked['Feature_name'].iloc[:(topn_feat)].values.tolist()\n",
    " from sklearn.model_selection import train_test_split\n",
    " \n",
    " train_x_cols,test_x_cols,train_y,test_y = train_test_split(x[test_cols],y,test_size=1/4, random_state=r)\n",
    " train_x_cols,val_x_cols,train_y,val_y= train_test_split(train_x_cols, train_y, test_size=1/3, random_state=r)\n",
    " train_x_cols = pd.DataFrame(scaler.fit_transform(train_x_cols),columns=test_cols)\n",
    " test_x_cols = pd.DataFrame(scaler.fit_transform(test_x_cols),columns=test_cols)\n",
    "\n",
    " model.fit(train_x_cols,train_y)\n",
    " test_predict = model.predict_proba(test_x_cols)\n",
    " test_preds_cols=test_predict[:,1]\n",
    " test_pred_cols=test_preds_cols\n",
    "\n",
    " for i in range(0, len(test_preds_cols)):\n",
    "  if(test_preds_cols[i]>breakval_):\n",
    "    test_pred_cols[i] = 1\n",
    "  else:\n",
    "    test_pred_cols[i] = 0\n",
    "    \n",
    " f1sco= f1(test_y,test_pred_cols)\n",
    " recall1 = recall_score(test_y,test_pred_cols)\n",
    " f1score.append(f1sco)\n",
    " recalllist.append(recall1)\n",
    " indexlist.append(i)\n",
    " topncollist.append(topn_feat)\n",
    " test_colslist.append(test_cols)\n",
    " predicted_wrt_evaluationmetrics.append(test_pred_cols)\n",
    " \n",
    " print(\"the f1 score has top \"+str(topfeat[testmetric][0])+\" features (chosen by rfe) where the evaluation metric \"+str(testmetric)+\" reaches the highest score: \"+str(topfeat[testmetric][1])+\" compared to other combination of feature used to make the model =\", f1sco,end= '\\n')\n",
    " cf= confusion_matrix(test_y, test_pred_cols)\n",
    " print( \"confusion matrix is : \",cf) \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "testtable=pd.DataFrame([topncollist,test_colslist,recalllist,f1score],index=['topn cols (rfe) which maximizes respective column metric','name of above cols','recall of above cols','f1score of above cols'],columns=eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topn cols (rfe) which maximizes respective column metric</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name of above cols</th>\n",
       "      <td>[Sex_female, Pclass_1, Age, SibSp_4, SibSp_3, ...</td>\n",
       "      <td>[Sex_female, Pclass_1, Age, SibSp_4, SibSp_3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall of above cols</th>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.784091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score of above cols</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               recall  \\\n",
       "topn cols (rfe) which maximizes respective colu...                                                 19   \n",
       "name of above cols                                  [Sex_female, Pclass_1, Age, SibSp_4, SibSp_3, ...   \n",
       "recall of above cols                                                                         0.784091   \n",
       "f1score of above cols                                                                        0.766667   \n",
       "\n",
       "                                                                                                   f1  \n",
       "topn cols (rfe) which maximizes respective colu...                                                 19  \n",
       "name of above cols                                  [Sex_female, Pclass_1, Age, SibSp_4, SibSp_3, ...  \n",
       "recall of above cols                                                                         0.784091  \n",
       "f1score of above cols                                                                        0.766667  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model below has been predicted by topn cols (rfe) wrt to maximizing  recall\n"
     ]
    }
   ],
   "source": [
    "print(\"the model below has been predicted by topn cols (rfe) wrt to maximizing \", eval_metric[0],end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_wrt_evaluationmetrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model below has been predicted by topn cols (rfe) wrt to maximizing  f1\n"
     ]
    }
   ],
   "source": [
    "print(\"the model below has been predicted by topn cols (rfe) wrt to maximizing \", eval_metric[1],end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_wrt_evaluationmetrics[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x,train_y)\n",
    "test_predict = model.predict_proba(test_x)\n",
    "test_preds=test_predict[:,1]\n",
    "test_pred=test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(test_preds)):\n",
    "  if(model.predict_proba(test_x)[:,1][i]>breakval_):\n",
    "    test_pred[i] = 1\n",
    "  else:\n",
    "    test_pred[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.770949720670391"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(test_y,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43106867292900525"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=model.predict_proba(test_x)[:,1]\n",
    "ll(test_y,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wq2nBd4yaJLy"
   },
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5082,
     "status": "ok",
     "timestamp": 1559907759167,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh5.googleusercontent.com/-72ZtNB76Qxg/AAAAAAAAAAI/AAAAAAAAAAc/Nsa5vQruND0/s64/photo.jpg",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "_B0y2DfFZus5",
    "outputId": "05523d3b-19cf-413d-d839-3514d278a29a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112  23]\n",
      " [ 19  69]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf= confusion_matrix(test_y, test_pred_cols)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[113  22]\n",
      " [ 19  69]]\n"
     ]
    }
   ],
   "source": [
    "cf= confusion_matrix(test_y, test_pred)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4795,
     "status": "ok",
     "timestamp": 1559907759171,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh5.googleusercontent.com/-72ZtNB76Qxg/AAAAAAAAAAI/AAAAAAAAAAc/Nsa5vQruND0/s64/photo.jpg",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "8iN2ugVDZkWS",
    "outputId": "26abffce-bb28-4786-81d6-ac09ad0e4402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       135\n",
      "           1       0.75      0.78      0.77        88\n",
      "\n",
      "    accuracy                           0.81       223\n",
      "   macro avg       0.80      0.81      0.80       223\n",
      "weighted avg       0.81      0.81      0.81       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report as rep\n",
    "print(rep( test_y , test_pred_cols ))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Logistic regression Notebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
